{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dcf611f",
   "metadata": {},
   "source": [
    "# Letterboxd Movie Recommender ‚Äî Notebook\n",
    "\n",
    "This notebook is a **complete, runnable starter** for the Letterboxd recommender project. It follows the architecture: Data load ‚Üí Cleaning ‚Üí TF-IDF (content) ‚Üí LDA ‚Üí Sentiment ‚Üí Collaborative (SVD/item-item) ‚Üí Hybrid recommendation. \n",
    "\n",
    "Place your CSV files in `letterboxd-movie-ratings-data/` with filenames:\n",
    "- `movie_data.csv`\n",
    "- `ratings_export.csv`\n",
    "- `users_export.csv`\n",
    "\n",
    "Run the cells in order. The notebook contains fallbacks so it runs even if some optional packages are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01791847",
   "metadata": {},
   "source": [
    "## 1) Setup ‚Äî Install dependencies (run once)\n",
    "\n",
    "Run the following cell to install required packages. If you are on Colab, uncomment the pip installs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e23824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import load_npz, vstack\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3fc2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.read_csv(\"merged_movies_ratings_users.csv\")\n",
    "movies = pd.read_csv(\"clean_movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac055e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged Index(['movie_id', 'username', 'movie_name', 'genres', 'rating', 'description',\n",
      "       'year'],\n",
      "      dtype='object') \n",
      "movies.columns: Index(['movie_id', 'movie_name', 'genres', 'description', 'year', 'popularity',\n",
      "       'vote_average', 'vote_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"merged\",\n",
    "      merged.columns,\n",
    "      \"\\nmovies.columns:\",\n",
    "      movies.columns,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4458a593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>username</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feast-2014</td>\n",
       "      <td>deathproof</td>\n",
       "      <td>Feast</td>\n",
       "      <td>[\"Animation\",\"Comedy\",\"Drama\",\"Family\"]</td>\n",
       "      <td>7</td>\n",
       "      <td>This Oscar-winning animated short film tells t...</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loving-2016</td>\n",
       "      <td>deathproof</td>\n",
       "      <td>Loving</td>\n",
       "      <td>[\"Romance\",\"Drama\"]</td>\n",
       "      <td>7</td>\n",
       "      <td>The story of Richard and Mildred Loving, an in...</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scripted-content</td>\n",
       "      <td>deathproof</td>\n",
       "      <td>Scripted Content</td>\n",
       "      <td>[\"Comedy\"]</td>\n",
       "      <td>7</td>\n",
       "      <td>A very short film for Vogue starring Jessica C...</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the-future</td>\n",
       "      <td>deathproof</td>\n",
       "      <td>The Future</td>\n",
       "      <td>[\"Drama\",\"Fantasy\",\"Romance\"]</td>\n",
       "      <td>4</td>\n",
       "      <td>When a couple decides to adopt a stray cat the...</td>\n",
       "      <td>2011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mank</td>\n",
       "      <td>deathproof</td>\n",
       "      <td>Mank</td>\n",
       "      <td>[\"Drama\",\"History\"]</td>\n",
       "      <td>5</td>\n",
       "      <td>1930s Hollywood is reevaluated through the eye...</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_id    username        movie_name  \\\n",
       "0        feast-2014  deathproof             Feast   \n",
       "1       loving-2016  deathproof            Loving   \n",
       "2  scripted-content  deathproof  Scripted Content   \n",
       "3        the-future  deathproof        The Future   \n",
       "4              mank  deathproof              Mank   \n",
       "\n",
       "                                    genres  rating  \\\n",
       "0  [\"Animation\",\"Comedy\",\"Drama\",\"Family\"]       7   \n",
       "1                      [\"Romance\",\"Drama\"]       7   \n",
       "2                               [\"Comedy\"]       7   \n",
       "3            [\"Drama\",\"Fantasy\",\"Romance\"]       4   \n",
       "4                      [\"Drama\",\"History\"]       5   \n",
       "\n",
       "                                         description    year  \n",
       "0  This Oscar-winning animated short film tells t...  2014.0  \n",
       "1  The story of Richard and Mildred Loving, an in...  2016.0  \n",
       "2  A very short film for Vogue starring Jessica C...  2014.0  \n",
       "3  When a couple decides to adopt a stray cat the...  2011.0  \n",
       "4  1930s Hollywood is reevaluated through the eye...  2020.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb848c",
   "metadata": {},
   "source": [
    "## 9 LOad models (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c10c9fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-K shapes: (285963, 10000) (285963, 10000)\n"
     ]
    }
   ],
   "source": [
    "topk_indices = np.load('topk_data/topk_indices.npy')\n",
    "topk_scores = np.load('topk_data/topk_scores.npy')\n",
    "print(\"Top-K shapes:\", topk_indices.shape, topk_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b756c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk_indices [[0.3175046  0.2466452  0.24578768 ... 0.02833881 0.0283383  0.02833725]\n",
      " [0.44509855 0.41655144 0.31313947 ... 0.02684237 0.02684129 0.02683994]\n",
      " [0.51007384 0.39329883 0.38868892 ... 0.02717405 0.02717189 0.0271715 ]\n",
      " ...\n",
      " [0.69548976 0.47076145 0.47064832 ... 0.         0.         0.        ]\n",
      " [0.6949353  0.62749654 0.58891606 ... 0.01979467 0.01979269 0.01978976]\n",
      " [0.49202397 0.47031456 0.43653703 ... 0.         0.         0.        ]] \n",
      "topk_scores [[236856 238306 207249 ... 185477 260989 234206]\n",
      " [252069  98307 116085 ...  76861  66098 243644]\n",
      " [ 96408 241070 228775 ... 272778 188872 161629]\n",
      " ...\n",
      " [159538 234413 163953 ...  92946  92947  92948]\n",
      " [ 85836 190023  80402 ... 203198  45521  52017]\n",
      " [ 29335  60155 248170 ...  92220  92219  92218]]\n"
     ]
    }
   ],
   "source": [
    "print(\"topk_indices\",\n",
    "      topk_scores,\n",
    "      \"\\ntopk_scores\",\n",
    "      topk_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba9265cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SVD collaborative model\n",
    "collab_model = joblib.load('svd_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b3a1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'surprise_svd',\n",
       " 'model': <surprise.prediction_algorithms.matrix_factorization.SVD at 0x24493de9d20>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collab_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08cbff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_batches_dir = 'fused_batches'\n",
    "batch_files = sorted([os.path.join(fused_batches_dir, f) for f in os.listdir(fused_batches_dir) if f.endswith('.npz')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3675d4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fused_batches\\\\fused_batch_0.npz',\n",
       " 'fused_batches\\\\fused_batch_1.npz',\n",
       " 'fused_batches\\\\fused_batch_10.npz',\n",
       " 'fused_batches\\\\fused_batch_11.npz',\n",
       " 'fused_batches\\\\fused_batch_12.npz',\n",
       " 'fused_batches\\\\fused_batch_13.npz',\n",
       " 'fused_batches\\\\fused_batch_14.npz',\n",
       " 'fused_batches\\\\fused_batch_15.npz',\n",
       " 'fused_batches\\\\fused_batch_16.npz',\n",
       " 'fused_batches\\\\fused_batch_17.npz',\n",
       " 'fused_batches\\\\fused_batch_18.npz',\n",
       " 'fused_batches\\\\fused_batch_19.npz',\n",
       " 'fused_batches\\\\fused_batch_2.npz',\n",
       " 'fused_batches\\\\fused_batch_20.npz',\n",
       " 'fused_batches\\\\fused_batch_21.npz',\n",
       " 'fused_batches\\\\fused_batch_22.npz',\n",
       " 'fused_batches\\\\fused_batch_23.npz',\n",
       " 'fused_batches\\\\fused_batch_24.npz',\n",
       " 'fused_batches\\\\fused_batch_25.npz',\n",
       " 'fused_batches\\\\fused_batch_26.npz',\n",
       " 'fused_batches\\\\fused_batch_27.npz',\n",
       " 'fused_batches\\\\fused_batch_28.npz',\n",
       " 'fused_batches\\\\fused_batch_3.npz',\n",
       " 'fused_batches\\\\fused_batch_4.npz',\n",
       " 'fused_batches\\\\fused_batch_5.npz',\n",
       " 'fused_batches\\\\fused_batch_6.npz',\n",
       " 'fused_batches\\\\fused_batch_7.npz',\n",
       " 'fused_batches\\\\fused_batch_8.npz',\n",
       " 'fused_batches\\\\fused_batch_9.npz']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94c2f097",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_batches = [load_npz(f) for f in batch_files]\n",
    "final_matrix = vstack(final_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bb5eb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 396536 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 399151 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 399840 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 399799 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 400621 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 395996 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 400712 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 398417 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 401200 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 400991 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 397217 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 397345 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 397500 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 387704 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 359765 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 345744 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 378045 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 373321 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 355198 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 330077 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 334838 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 214081 stored elements and shape (5963, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 399380 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 398218 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 396755 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 397386 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 400035 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 401589 stored elements and shape (10000, 100011)>,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 398838 stored elements and shape (10000, 100011)>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7e93f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 11056299 stored elements and shape (285963, 100011)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d89461",
   "metadata": {},
   "source": [
    "## 10) Hybrid recommendation function (content + collaborative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ed88469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged.columns: Index(['movie_id', 'username', 'movie_name', 'genres', 'rating', 'description',\n",
      "       'year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"merged.columns:\", merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d17e11cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.columns: Index(['movie_id', 'movie_name', 'genres', 'description', 'year', 'popularity',\n",
      "       'vote_average', 'vote_count'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"movies.columns:\", movies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86b0ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user_topk(username, merged_df, movies_df, topk_indices, topk_scores, collab_model, \n",
    "                            top_n=10, weight_collab=0.5, weight_popularity=0.3):\n",
    "    # 1Ô∏è‚É£ Get user‚Äôs ratings\n",
    "    user_ratings = merged_df[merged_df['username'].astype(str).str.lower() == str(username).lower()]\n",
    "    if user_ratings.empty:\n",
    "        print(\"User not found or no ratings.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    seen = set(user_ratings['movie_id'].unique())\n",
    "    candidates = movies_df[~movies_df['movie_id'].isin(seen)].copy()\n",
    "    if candidates.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2Ô∏è‚É£ Content-based score (from Top-K similarity)\n",
    "    movie_index = {m: i for i, m in enumerate(movies_df['movie_id'].tolist())}\n",
    "    candidate_indices = [movie_index[m] for m in candidates['movie_id'] if m in movie_index]\n",
    "\n",
    "    content_scores = []\n",
    "    for idx in candidate_indices:\n",
    "        sims = topk_scores[idx]\n",
    "        content_scores.append(float(np.mean(sims)))\n",
    "    content_scores = np.array(content_scores)\n",
    "\n",
    "    # 3Ô∏è‚É£ Collaborative filtering score\n",
    "    collab_scores = np.zeros(len(candidates), dtype=float)\n",
    "    if collab_model['type'] == 'surprise_svd':\n",
    "        algo = collab_model['model']\n",
    "        for i, mid in enumerate(candidates['movie_id']):\n",
    "            try:\n",
    "                pred = algo.predict(uid=username, iid=mid)\n",
    "                collab_scores[i] = pred.est\n",
    "            except:\n",
    "                collab_scores[i] = 0.0\n",
    "    else:\n",
    "        sim_matrix = collab_model['sim_matrix']\n",
    "        id_to_index = collab_model['id_to_index']\n",
    "        seen_indices = [id_to_index.get(m) for m in seen if id_to_index.get(m) is not None]\n",
    "        for i, mid in enumerate(candidates['movie_id']):\n",
    "            idx = id_to_index.get(mid)\n",
    "            if idx is None or not seen_indices:\n",
    "                collab_scores[i] = 0.0\n",
    "            else:\n",
    "                sims = sim_matrix[idx, seen_indices]\n",
    "                collab_scores[i] = float(np.mean(sims)) if len(sims) > 0 else 0.0\n",
    "\n",
    "    # 4Ô∏è‚É£ Normalization helper\n",
    "    def norm(a):\n",
    "        a = np.array(a, dtype=float)\n",
    "        if a.max() == a.min():\n",
    "            return np.zeros_like(a)\n",
    "        return (a - a.min()) / (a.max() - a.min())\n",
    "\n",
    "    c1 = norm(content_scores)\n",
    "    c2 = norm(collab_scores)\n",
    "\n",
    "    # 5Ô∏è‚É£ Popularity boost (Letterboxd)\n",
    "    if 'vote_average' in candidates.columns and 'vote_count' in candidates.columns:\n",
    "        popularity_boost = np.log1p(candidates['vote_count'].fillna(0)) * candidates['vote_average'].fillna(0)\n",
    "        c3 = norm(popularity_boost)\n",
    "    else:\n",
    "        c3 = np.zeros(len(candidates))\n",
    "\n",
    "    # 6Ô∏è‚É£ Combine all scores\n",
    "    #   final = (1 - weight_collab - weight_popularity)*content + weight_collab*collab + weight_popularity*popularity\n",
    "    w_content = 1 - weight_collab - weight_popularity\n",
    "    final = w_content * c1 + weight_collab * c2 + weight_popularity * c3\n",
    "\n",
    "    # 7Ô∏è‚É£ Prepare results\n",
    "    candidates = candidates.reset_index(drop=True)\n",
    "    candidates['content_score'] = c1\n",
    "    candidates['collab_score'] = c2\n",
    "    candidates['popularity_score'] = c3\n",
    "    candidates['final_score'] = final\n",
    "\n",
    "    # 8Ô∏è‚É£ Return top-N with movie_name, year, rating info\n",
    "    cols = ['movie_name','description', 'year', 'vote_average', 'vote_count', \n",
    "            'content_score', 'collab_score', 'popularity_score', 'final_score']\n",
    "    for c in cols:\n",
    "        if c not in candidates.columns:\n",
    "            candidates[c] = None\n",
    "\n",
    "    return candidates.sort_values('final_score', ascending=False).head(top_n)[cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40cad868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>content_score</th>\n",
       "      <th>collab_score</th>\n",
       "      <th>popularity_score</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84473</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>empire strike back empire strike back epic sag...</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>13524.0</td>\n",
       "      <td>0.229719</td>\n",
       "      <td>0.868782</td>\n",
       "      <td>0.954879</td>\n",
       "      <td>0.894611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192647</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>silence lamb silence lamb clarice starling top...</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>12567.0</td>\n",
       "      <td>0.234908</td>\n",
       "      <td>0.865171</td>\n",
       "      <td>0.936233</td>\n",
       "      <td>0.886489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6058</th>\n",
       "      <td>Life Is Beautiful</td>\n",
       "      <td>life beautiful life beautiful touching story i...</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>10571.0</td>\n",
       "      <td>0.293478</td>\n",
       "      <td>0.832868</td>\n",
       "      <td>0.941225</td>\n",
       "      <td>0.865375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197622</th>\n",
       "      <td>Wild Tales</td>\n",
       "      <td>wild tale wild tale six deadly story explore e...</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2467.0</td>\n",
       "      <td>0.256807</td>\n",
       "      <td>0.915707</td>\n",
       "      <td>0.737440</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156930</th>\n",
       "      <td>V for Vendetta</td>\n",
       "      <td>vendetta vendetta world great britain become f...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>11656.0</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>0.836083</td>\n",
       "      <td>0.884009</td>\n",
       "      <td>0.850461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22621</th>\n",
       "      <td>Kizumonogatari Part 2: Nekketsu</td>\n",
       "      <td>kizumonogatari part nekketsu kizumonogatari pa...</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.285082</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.461795</td>\n",
       "      <td>0.838397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154645</th>\n",
       "      <td>Moulin Rouge!</td>\n",
       "      <td>moulin rouge 2001 moulin rouge celebration lov...</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>0.187750</td>\n",
       "      <td>0.877592</td>\n",
       "      <td>0.745250</td>\n",
       "      <td>0.837889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30970</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>godfather part godfather part continuing saga ...</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9035.0</td>\n",
       "      <td>0.265044</td>\n",
       "      <td>0.791682</td>\n",
       "      <td>0.936163</td>\n",
       "      <td>0.835026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68741</th>\n",
       "      <td>10 Things I Hate About You</td>\n",
       "      <td>thing hate thing hate first day new school cam...</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6128.0</td>\n",
       "      <td>0.272571</td>\n",
       "      <td>0.853248</td>\n",
       "      <td>0.792051</td>\n",
       "      <td>0.834889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52055</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>terminator judgment day terminator judgment da...</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9815.0</td>\n",
       "      <td>0.249247</td>\n",
       "      <td>0.807602</td>\n",
       "      <td>0.889750</td>\n",
       "      <td>0.832247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             movie_name  \\\n",
       "84473           The Empire Strikes Back   \n",
       "192647         The Silence of the Lambs   \n",
       "6058                  Life Is Beautiful   \n",
       "197622                       Wild Tales   \n",
       "156930                   V for Vendetta   \n",
       "22621   Kizumonogatari Part 2: Nekketsu   \n",
       "154645                    Moulin Rouge!   \n",
       "30970            The Godfather: Part II   \n",
       "68741        10 Things I Hate About You   \n",
       "52055        Terminator 2: Judgment Day   \n",
       "\n",
       "                                              description    year  \\\n",
       "84473   empire strike back empire strike back epic sag...  1980.0   \n",
       "192647  silence lamb silence lamb clarice starling top...  1991.0   \n",
       "6058    life beautiful life beautiful touching story i...  1997.0   \n",
       "197622  wild tale wild tale six deadly story explore e...  2014.0   \n",
       "156930  vendetta vendetta world great britain become f...  2005.0   \n",
       "22621   kizumonogatari part nekketsu kizumonogatari pa...  2016.0   \n",
       "154645  moulin rouge 2001 moulin rouge celebration lov...  2001.0   \n",
       "30970   godfather part godfather part continuing saga ...  1974.0   \n",
       "68741   thing hate thing hate first day new school cam...  1999.0   \n",
       "52055   terminator judgment day terminator judgment da...  1991.0   \n",
       "\n",
       "        vote_average  vote_count  content_score  collab_score  \\\n",
       "84473            8.4     13524.0       0.229719      0.868782   \n",
       "192647           8.3     12567.0       0.234908      0.865171   \n",
       "6058             8.5     10571.0       0.293478      0.832868   \n",
       "197622           7.9      2467.0       0.256807      0.915707   \n",
       "156930           7.9     11656.0       0.220366      0.836083   \n",
       "22621            8.1       117.0       0.285082      0.999798   \n",
       "154645           7.6      3660.0       0.187750      0.877592   \n",
       "30970            8.6      9035.0       0.265044      0.791682   \n",
       "68741            7.6      6128.0       0.272571      0.853248   \n",
       "52055            8.1      9815.0       0.249247      0.807602   \n",
       "\n",
       "        popularity_score  final_score  \n",
       "84473           0.954879     0.894611  \n",
       "192647          0.936233     0.886489  \n",
       "6058            0.941225     0.865375  \n",
       "197622          0.737440     0.862227  \n",
       "156930          0.884009     0.850461  \n",
       "22621           0.461795     0.838397  \n",
       "154645          0.745250     0.837889  \n",
       "30970           0.936163     0.835026  \n",
       "68741           0.792051     0.834889  \n",
       "52055           0.889750     0.832247  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_user = merged['username'].dropna().astype(str).iloc[0]\n",
    "recos = recommend_for_user_topk(example_user, merged, movies, topk_indices, topk_scores, collab_model, top_n=10, weight_collab=0.7)\n",
    "if not recos.empty:\n",
    "    display(recos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8373723f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13524.0\n"
     ]
    }
   ],
   "source": [
    "print(recos['vote_count'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5473cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_recommendations(recos, movies):\n",
    "    \"\"\"\n",
    "    Display movie recommendations with poster, title, year, and rating info.\n",
    "    \"\"\"\n",
    "    if recos is None or recos.empty:\n",
    "        display(HTML(\"<p style='color:red;'>No recommendations to display.</p>\"))\n",
    "        return\n",
    "\n",
    "    html = \"\"\"\n",
    "    <style>\n",
    "        .movie-card {\n",
    "            display: flex;\n",
    "            align-items: center;\n",
    "            margin-bottom: 10px;\n",
    "            background-color: #f8f9fa;\n",
    "            border-radius: 10px;\n",
    "            padding: 10px;\n",
    "            box-shadow: 0 1px 4px rgba(0,0,0,0.1);\n",
    "        }\n",
    "        .movie-card img {\n",
    "            border-radius: 8px;\n",
    "            width: 80px;\n",
    "            height: 120px;\n",
    "            object-fit: cover;\n",
    "            margin-right: 12px;\n",
    "        }\n",
    "        .movie-info {\n",
    "            font-family: Arial, sans-serif;\n",
    "        }\n",
    "        .movie-title {\n",
    "            font-size: 16px;\n",
    "            font-weight: bold;\n",
    "        }\n",
    "        .movie-meta {\n",
    "            font-size: 13px;\n",
    "            color: #555;\n",
    "        }\n",
    "    </style>\n",
    "    <h3>üé¨ Recommended Movies</h3>\n",
    "    \"\"\"\n",
    "\n",
    "    for _, row in recos.iterrows():\n",
    "        movie = movies[movies['movie_id'] == row['movie_id']].iloc[0] if 'movie_id' in recos.columns else row\n",
    "        img = movie.get('image_url', '') or \"https://via.placeholder.com/100x150?text=No+Image\"\n",
    "        year = movie.get('year', 'N/A')\n",
    "        rating = movie.get('vote_average', 'N/A')\n",
    "        votes = movie.get('vote_count', 'N/A')\n",
    "\n",
    "        html += f\"\"\"\n",
    "        <div class=\"movie-card\">\n",
    "            <img src=\"{img}\">\n",
    "            <div class=\"movie-info\">\n",
    "                <div class=\"movie-title\">{row['title']} ({year})</div>\n",
    "                <div class=\"movie-meta\">\n",
    "                    ‚≠ê Rating: {rating} ({votes} votes)<br>\n",
    "                    üß† Content: {row['content_score']:.3f} |\n",
    "                    üë• Collab: {row['collab_score']:.3f} |\n",
    "                    üî• Final: {row['final_score']:.3f}\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    display(HTML(html))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dd44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_recommendations(recos, movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "test_users = ['filipe_furtado', 'abluevelvets', 'riverjphoenix', 'jay']\n",
    "\n",
    "for user in test_users:\n",
    "    print(f\"\\nüîπ Recommendations for {user}:\")\n",
    "    recos = recommend_for_user_topk(\n",
    "        username=user,\n",
    "        merged_df=merged,\n",
    "        movies_df=movies,\n",
    "        topk_indices=topk_indices,\n",
    "        topk_scores=topk_scores,\n",
    "        collab_model=collab_model,\n",
    "        top_n=5,\n",
    "        weight_collab=0.7\n",
    "    )\n",
    "    \n",
    "    if recos is None or recos.empty:\n",
    "        print(\"‚ö†Ô∏è No recommendations found (user not in dataset or no ratings).\")\n",
    "        continue\n",
    "\n",
    "    # Pretty display\n",
    "    top_recos = recos.sort_values('final_score', ascending=False).head(5)\n",
    "    html = \"<ul>\"\n",
    "    for _, row in top_recos.iterrows():\n",
    "        html += f\"<li><b>{row['title']}</b> ‚Äî Final Score: {row['final_score']:.3f}</li>\"\n",
    "    html += \"</ul>\"\n",
    "    display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de79fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "class FastLetterboxdRecommender:\n",
    "    def __init__(self, topk_indices_path, topk_scores_path, svd_model_path, movies_df_path):\n",
    "        \"\"\"Load your pre-trained models\"\"\"\n",
    "        print(\"Loading models...\")\n",
    "        self.topk_indices = topk_indices_path\n",
    "        self.topk_scores = topk_scores_path\n",
    "        self.collab_model = svd_model_path\n",
    "        self.movies_df = movies_df_path\n",
    "        self.movie_index = {m: i for i, m in enumerate(self.movies_df['movie_id'].tolist())}\n",
    "        \n",
    "        self.base_url = \"https://letterboxd.com\"\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        print(\"‚úì Models loaded successfully\\n\")\n",
    "    \n",
    "    def get_user_sample_films(self, username, max_films=50, strategy='smart'):\n",
    "        \"\"\"\n",
    "        Fast sampling strategies:\n",
    "        - 'smart': Get recent + highly rated films only\n",
    "        - 'random': Random sample across all pages\n",
    "        - 'first_pages': Just first few pages\n",
    "        \"\"\"\n",
    "        print(f\"üé¨ Fetching sample films for user: {username}\")\n",
    "        print(f\"Strategy: {strategy}, Max films: {max_films}\\n\")\n",
    "        \n",
    "        if strategy == 'smart':\n",
    "            return self._get_smart_sample(username, max_films)\n",
    "        elif strategy == 'random':\n",
    "            return self._get_random_sample(username, max_films)\n",
    "        else:\n",
    "            return self._get_first_pages(username, max_films)\n",
    "    \n",
    "    def _get_smart_sample(self, username, max_films):\n",
    "        \"\"\"\n",
    "        Smart sampling: Get highest rated + most recent films\n",
    "        This gives best representation of user taste\n",
    "        \"\"\"\n",
    "        films = []\n",
    "        \n",
    "        # 1. Get highly rated films (5 stars, 4.5 stars)\n",
    "        print(\"  ‚Üí Fetching highly rated films...\")\n",
    "        for rating in ['rated/5', 'rated/4.5']:\n",
    "            url = f\"{self.base_url}/{username}/films/{rating}/\"\n",
    "            page_films = self._scrape_page_fast(url, limit=max_films // 3)\n",
    "            films.extend(page_films)\n",
    "            if len(films) >= max_films:\n",
    "                break\n",
    "        \n",
    "        # 2. Get recent films (diary - recently watched)\n",
    "        if len(films) < max_films:\n",
    "            print(\"  ‚Üí Fetching recent films from diary...\")\n",
    "            url = f\"{self.base_url}/{username}/films/diary/\"\n",
    "            recent_films = self._scrape_page_fast(url, limit=max_films - len(films))\n",
    "            films.extend(recent_films)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        seen = set()\n",
    "        unique_films = []\n",
    "        for f in films:\n",
    "            if f['movie_id'] not in seen:\n",
    "                seen.add(f['movie_id'])\n",
    "                unique_films.append(f)\n",
    "        \n",
    "        print(f\"  ‚úì Collected {len(unique_films)} unique films\\n\")\n",
    "        return unique_films[:max_films]\n",
    "    \n",
    "    def _get_first_pages(self, username, max_films):\n",
    "        \"\"\"Just scrape first few pages - fastest but less accurate\"\"\"\n",
    "        print(\"  ‚Üí Fetching first pages...\")\n",
    "        url = f\"{self.base_url}/{username}/films/\"\n",
    "        films = self._scrape_page_fast(url, limit=max_films)\n",
    "        print(f\"  ‚úì Collected {len(films)} films\\n\")\n",
    "        return films\n",
    "    \n",
    "    def _scrape_page_fast(self, url, limit=50):\n",
    "        \"\"\"Fast scraping - only get movie IDs and ratings, skip detailed info\"\"\"\n",
    "        films = []\n",
    "        page = 1\n",
    "        \n",
    "        while len(films) < limit:\n",
    "            page_url = f\"{url}page/{page}/\" if page > 1 else url\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(page_url, headers=self.headers, timeout=5)\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                \n",
    "                movie_items = soup.find_all('div', class_='react-component', \n",
    "                                           attrs={'data-target-link': True})\n",
    "                \n",
    "                if not movie_items:\n",
    "                    break\n",
    "                \n",
    "                for item in movie_items:\n",
    "                    if len(films) >= limit:\n",
    "                        break\n",
    "                    \n",
    "                    target_link = item.get('data-target-link', '')\n",
    "                    if '/film/' not in target_link:\n",
    "                        continue\n",
    "                    \n",
    "                    movie_slug = target_link.strip('/').split('/')[-1]\n",
    "                    \n",
    "                    # Extract rating from parent if exists\n",
    "                    rating = self._extract_rating_fast(item)\n",
    "                    \n",
    "                    films.append({\n",
    "                        'movie_id': movie_slug,\n",
    "                        'rating': rating\n",
    "                    })\n",
    "                \n",
    "                if len(films) >= limit or len(movie_items) == 0:\n",
    "                    break\n",
    "                \n",
    "                page += 1\n",
    "                time.sleep(0.3)  # Minimal delay\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Error on page {page}: {e}\")\n",
    "                break\n",
    "        \n",
    "        return films\n",
    "    \n",
    "    def _extract_rating_fast(self, item):\n",
    "        \"\"\"Quick rating extraction\"\"\"\n",
    "        parent = item.find_parent('li')\n",
    "        if parent:\n",
    "            rating_span = parent.find('span', class_=lambda x: x and 'rated-' in str(x))\n",
    "            if rating_span:\n",
    "                classes = rating_span.get('class', [])\n",
    "                for cls in classes:\n",
    "                    if cls.startswith('rated-'):\n",
    "                        try:\n",
    "                            rating_value = int(cls.split('-')[1])\n",
    "                            return rating_value / 2.0\n",
    "                        except:\n",
    "                            pass\n",
    "        return None\n",
    "    \n",
    "    def recommend_for_new_user(self, username, user_films, top_n=10, \n",
    "                               weight_collab=0.3, weight_popularity=0.4):\n",
    "        \"\"\"\n",
    "        Generate recommendations for a new Letterboxd user\n",
    "        \n",
    "        Since user is not in training data:\n",
    "        - Reduce collab weight (can't use SVD effectively)\n",
    "        - Increase content + popularity weights\n",
    "        \"\"\"\n",
    "        print(f\"üéØ Generating recommendations for {username}...\\n\")\n",
    "        \n",
    "        # Get movie IDs user has seen\n",
    "        seen_ids = set([f['movie_id'] for f in user_films])\n",
    "        \n",
    "        # Filter candidates (movies not seen)\n",
    "        candidates = self.movies_df[~self.movies_df['movie_id'].isin(seen_ids)].copy()\n",
    "        \n",
    "        if candidates.empty:\n",
    "            print(\"No candidates found!\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Map seen films to indices\n",
    "        seen_indices = [self.movie_index[mid] for mid in seen_ids \n",
    "                       if mid in self.movie_index]\n",
    "        \n",
    "        if not seen_indices:\n",
    "            print(\"‚ö†Ô∏è  No matching films found in training data\")\n",
    "            print(\"Returning popular films instead...\\n\")\n",
    "            return self._get_popular_recommendations(top_n)\n",
    "        \n",
    "        # ===== CONTENT-BASED SCORING =====\n",
    "        print(\"  ‚Üí Computing content-based scores...\")\n",
    "        candidate_indices = [self.movie_index[m] for m in candidates['movie_id'] \n",
    "                           if m in self.movie_index]\n",
    "        \n",
    "        content_scores = []\n",
    "        for idx in candidate_indices:\n",
    "            # Get similarity to user's watched films\n",
    "            similarities = []\n",
    "            for seen_idx in seen_indices:\n",
    "                # Find if seen_idx is in topk neighbors of idx\n",
    "                neighbors = self.topk_indices[idx]\n",
    "                if seen_idx in neighbors:\n",
    "                    pos = np.where(neighbors == seen_idx)[0][0]\n",
    "                    similarities.append(self.topk_scores[idx][pos])\n",
    "            \n",
    "            if similarities:\n",
    "                content_scores.append(np.mean(similarities))\n",
    "            else:\n",
    "                content_scores.append(0.0)\n",
    "        \n",
    "        content_scores = np.array(content_scores)\n",
    "        \n",
    "        # ===== PSEUDO-COLLABORATIVE SCORE =====\n",
    "        # Use average rating of similar films\n",
    "        print(\"  ‚Üí Computing collaborative scores...\")\n",
    "        collab_scores = np.zeros(len(candidates))\n",
    "        \n",
    "        user_ratings = [f['rating'] for f in user_films if f['rating'] is not None]\n",
    "        if user_ratings:\n",
    "            avg_user_rating = np.mean(user_ratings)\n",
    "            # Weight by content similarity\n",
    "            collab_scores = content_scores * avg_user_rating\n",
    "        \n",
    "        # ===== POPULARITY SCORE =====\n",
    "        print(\"  ‚Üí Computing popularity scores...\")\n",
    "        if 'vote_average' in candidates.columns and 'vote_count' in candidates.columns:\n",
    "            popularity = (np.log1p(candidates['vote_count'].fillna(0)) * \n",
    "                         candidates['vote_average'].fillna(0))\n",
    "        else:\n",
    "            popularity = np.zeros(len(candidates))\n",
    "        \n",
    "        # ===== NORMALIZATION =====\n",
    "        def normalize(arr):\n",
    "            arr = np.array(arr, dtype=float)\n",
    "            if arr.max() == arr.min():\n",
    "                return np.zeros_like(arr)\n",
    "            return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "        \n",
    "        c1 = normalize(content_scores)\n",
    "        c2 = normalize(collab_scores)\n",
    "        c3 = normalize(popularity)\n",
    "        \n",
    "        # ===== FINAL SCORE =====\n",
    "        w_content = 1 - weight_collab - weight_popularity\n",
    "        final_score = w_content * c1 + weight_collab * c2 + weight_popularity * c3\n",
    "        \n",
    "        # ===== PREPARE RESULTS =====\n",
    "        candidates = candidates.reset_index(drop=True)\n",
    "        candidates['content_score'] = c1\n",
    "        candidates['collab_score'] = c2\n",
    "        candidates['popularity_score'] = c3\n",
    "        candidates['final_score'] = final_score\n",
    "        \n",
    "        # Select columns for output\n",
    "        output_cols = ['movie_id', 'movie_name', 'year', 'genres', 'vote_average', 'vote_count',\n",
    "                      'content_score', 'collab_score', 'final_score']\n",
    "        \n",
    "        # Filter to only existing columns\n",
    "        output_cols = [c for c in output_cols if c in candidates.columns]\n",
    "        \n",
    "        results = candidates.nlargest(top_n, 'final_score')[output_cols]\n",
    "        \n",
    "        print(f\"  ‚úì Generated {len(results)} recommendations\\n\")\n",
    "        return results\n",
    "    \n",
    "    def _get_popular_recommendations(self, top_n):\n",
    "        \"\"\"Fallback: return popular films\"\"\"\n",
    "        if 'vote_average' in self.movies_df.columns and 'vote_count' in self.movies_df.columns:\n",
    "            popular = self.movies_df.copy()\n",
    "            popular['popularity'] = (np.log1p(popular['vote_count'].fillna(0)) * \n",
    "                                    popular['vote_average'].fillna(0))\n",
    "            return popular.nlargest(top_n, 'popularity')[\n",
    "                ['movie_id', 'title', 'year', 'vote_average', 'vote_count']\n",
    "            ]\n",
    "        return self.movies_df.head(top_n)\n",
    "    \n",
    "    def recommend_realtime(self, username, max_films=50, top_n=10, strategy='smart'):\n",
    "        \"\"\"\n",
    "        Main function: Real-time recommendations for any Letterboxd user\n",
    "        \n",
    "        Args:\n",
    "            username: Letterboxd username\n",
    "            max_films: Max films to sample (30-50 is optimal for speed)\n",
    "            top_n: Number of recommendations to return\n",
    "            strategy: 'smart', 'first_pages', or 'random'\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with top-N recommendations\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(f\"üé¨ LETTERBOXD REAL-TIME RECOMMENDER\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Username: {username}\")\n",
    "        print(f\"Max sample size: {max_films}\")\n",
    "        print(f\"Strategy: {strategy}\\n\")\n",
    "        \n",
    "        # Step 1: Fast scraping\n",
    "        user_films = self.get_user_sample_films(username, max_films, strategy)\n",
    "        \n",
    "        if not user_films:\n",
    "            print(\"‚ùå No films found for this user\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Step 2: Generate recommendations\n",
    "        recommendations = self.recommend_for_new_user(\n",
    "            username, user_films, top_n=top_n,\n",
    "            weight_collab=0.2,  # Lower weight since user not in training\n",
    "            weight_popularity=0.4  # Higher weight for popularity\n",
    "        )\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        print(\"=\"*70)\n",
    "        print(f\"‚úÖ COMPLETED in {elapsed:.2f} seconds\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac1fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# USAGE EXAMPLE\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize recommender with your saved models\n",
    "    recommender = FastLetterboxdRecommender(\n",
    "        topk_indices_path=topk_indices,\n",
    "        topk_scores_path=topk_scores,\n",
    "        svd_model_path=collab_model,\n",
    "        movies_df_path=movies  # Your movies dataset\n",
    "    )\n",
    "    \n",
    "    # Get real-time recommendations for any Letterboxd user\n",
    "    username = \"marwanmovies\"  # Change to any username\n",
    "    \n",
    "    recommendations = recommender.recommend_realtime(\n",
    "        username=username,\n",
    "        max_films=40,  # Sample 40 most representative films\n",
    "        top_n=10,      # Return top 10 recommendations\n",
    "        strategy='smart'  # Use smart sampling\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüéØ TOP RECOMMENDATIONS:\")\n",
    "    print(\"=\"*70)\n",
    "    print(recommendations.to_string(index=False))\n",
    "    \n",
    "    # Save to CSV\n",
    "    recommendations.to_csv(f'{username}_recommendations.csv', index=False)\n",
    "    print(f\"\\n‚úÖ Saved to {username}_recommendations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0bba789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "‚úì Models loaded successfully\n",
      "\n",
      "======================================================================\n",
      "üé¨ LETTERBOXD REAL-TIME RECOMMENDER\n",
      "======================================================================\n",
      "Username: marwanmovies\n",
      "Max sample size: 40\n",
      "Strategy: smart\n",
      "\n",
      "üé¨ Fetching sample films for user: marwanmovies\n",
      "Strategy: smart, Max films: 40\n",
      "\n",
      "  ‚Üí Fetching highly rated films...\n",
      "  ‚Üí Fetching recent films from diary...\n",
      "  ‚úì Collected 37 unique films\n",
      "\n",
      "üéØ Generating recommendations for marwanmovies...\n",
      "\n",
      "  ‚Üí Computing content-based scores...\n",
      "  ‚Üí Computing collaborative scores...\n",
      "  ‚Üí Computing popularity scores...\n",
      "  ‚úì Generated 10 recommendations\n",
      "\n",
      "======================================================================\n",
      "‚úÖ COMPLETED in 167.21 seconds\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "recommender = FastLetterboxdRecommender(\n",
    "       topk_indices_path=topk_indices,\n",
    "       topk_scores_path=topk_scores,\n",
    "       svd_model_path=collab_model,\n",
    "       movies_df_path=movies  # Your movies dataset\n",
    "   )\n",
    "\n",
    "# Get recommendations in ~10 seconds!\n",
    "recs = recommender.recommend_realtime(\n",
    "    username=\"marwanmovies\",\n",
    "    max_films=40,  # Optimal balance\n",
    "    top_n=10,\n",
    "    strategy='smart'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
